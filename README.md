**Project Introduction** 

In this notebook, the main goal is to use **Spark SQL & PySpark** for big data analysis. 

Data used is open-source SF crime data from the following link: \
(https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-Historical-2003/tmnf-yvry).

Project Member: Hao(Charlotte) Jin \
Project Finish Date: Apr 20th, 2025 

***Using Databricks to view published Spark Notebook:*** \
(https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2771309616035809/2034731951719406/1828679416467169/latest.html).

\
\
**Table of contents:**

<summary>Project Introduction</summary>

- Import package  
- Download data  
- Load data as TempView  


<summary>Conducting OLAP Tasks:</summary>

- Analysis on: the number of crimes for different district  
- Analysis on: the number of crime by month in 2015, 2016, 2017, 2018.  
- Analysis on: the number of crime with respect to hours of certain days  
- Analysis on: how to distribute the police force smartly  
- Analysis on: the percentage of resolution for different category of crime, and provide suggestions  
- Analysis on: the Central Market/Tenderloin Boundary in specific due to high traffic  


<summary>Conclusion</summary>

- Discover and suggestions  


<summary>Appendix</summary>

- Notes on UDF  
